{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from numpy import vstack\nfrom numpy import sqrt\nfrom pandas import read_csv\nfrom sklearn.metrics import mean_squared_error\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch import Tensor\nfrom torch.nn import Linear\nfrom torch.nn import Sigmoid\nfrom torch.nn import Module\nfrom torch.optim import SGD\nfrom torch.nn import MSELoss\nfrom torch.nn.init import xavier_uniform_\nfrom tqdm import tqdm\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:04.988516Z","iopub.execute_input":"2023-11-12T19:38:04.988935Z","iopub.status.idle":"2023-11-12T19:38:04.997130Z","shell.execute_reply.started":"2023-11-12T19:38:04.988905Z","shell.execute_reply":"2023-11-12T19:38:04.995906Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# dataset definition perparation \nclass CSVDataset(Dataset):\n    # load the dataset\n    def __init__(self, path):\n        # load the csv file as a dataframe\n        df = read_csv(path, header=None , low_memory=False)\n        \n        df.head()\n        # store the inputs and outputs\n        self.X = df.values[1:, 2:6].astype('float32')  # Selecting columns 3 to 6 (indexing is 0-based)\n        self.y = df.values[1:, -1].astype('float32')\n        # ensure target has the right shape\n        self.y = self.y.reshape((len(self.y), 1))\n \n    # number of rows in the dataset\n    def __len__(self):\n        return len(self.X)\n \n    # get a row at an index\n    def __getitem__(self, idx):\n        return [self.X[idx], self.y[idx]]\n \n    # get indexes for train and test rows\n    def get_splits(self, n_test=0.33):\n        # determine sizes\n        test_size = round(n_test * len(self.X))\n        train_size = len(self.X) - test_size\n        # calculate the split\n        return random_split(self, [train_size, test_size])","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.045388Z","iopub.status.idle":"2023-11-12T19:38:05.045887Z","shell.execute_reply.started":"2023-11-12T19:38:05.045644Z","shell.execute_reply":"2023-11-12T19:38:05.045670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import Module, Linear, ReLU\nfrom torch.nn.init import xavier_uniform_\n\nclass MLP(Module):\n    # define model elements\n    def __init__(self, n_inputs):\n        super(MLP, self).__init__()\n        # input to the first hidden layer\n        self.hidden1 = Linear(n_inputs, 10)\n        xavier_uniform_(self.hidden1.weight)\n        self.act1 = ReLU()  # Change to ReLU\n        # second hidden layer\n        self.hidden2 = Linear(10, 8)\n        xavier_uniform_(self.hidden2.weight)\n        self.act2 = ReLU()  # Change to ReLU\n        # third hidden layer and output\n        self.hidden3 = Linear(8, 1)\n        xavier_uniform_(self.hidden3.weight)\n \n    # forward propagate input\n    def forward(self, X):\n        # input to the first hidden layer\n        X = self.hidden1(X)\n        X = self.act1(X)\n        # second hidden layer\n        X = self.hidden2(X)\n        X = self.act2(X)\n        # third hidden layer and output\n        X = self.hidden3(X)\n        return X\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.048191Z","iopub.status.idle":"2023-11-12T19:38:05.048656Z","shell.execute_reply.started":"2023-11-12T19:38:05.048412Z","shell.execute_reply":"2023-11-12T19:38:05.048432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare the dataset\ndef prepare_data(path ):\n    # load the dataset\n    dataset = CSVDataset(path)\n    \n   \n    # calculate split\n    train, test = dataset.get_splits()\n    # prepare data loaders\n    train_dl = DataLoader(train, batch_size=1024, shuffle=True)\n    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n    return train_dl, test_dl\n \n# train the model\ndef train_model(train_dl, model):\n    size = len(train_dl.dataset)\n    # define the optimization\n    criterion = MSELoss()\n    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n    # enumerate epochs\n    # enumerate epochs\n    for epoch in tqdm(range(30),desc='Training Epochs'):\n        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n        # enumerate mini batches\n        for batch, (inputs, targets) in enumerate(train_dl):\n            # clear the gradients\n            optimizer.zero_grad()\n            # compute the model output\n            yhat = model(inputs)\n            # calculate loss\n            loss = criterion(yhat, targets)\n            # credit assignment\n            loss.backward()\n            # update model weights\n            optimizer.step()\n           \n            #if batch % 100 == 0:\n        loss, current = loss.item(), batch * len(inputs)\n        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n ","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.050123Z","iopub.status.idle":"2023-11-12T19:38:05.051744Z","shell.execute_reply.started":"2023-11-12T19:38:05.051485Z","shell.execute_reply":"2023-11-12T19:38:05.051507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate the model\ndef evaluate_model(test_dl, model):\n    predictions, actuals = list(), list()\n    for i, (inputs, targets) in enumerate(test_dl):\n        # evaluate the model on the test set\n        yhat = model(inputs)\n        # retrieve numpy array\n        yhat = yhat.detach().numpy()\n        actual = targets.numpy()\n        actual = actual.reshape((len(actual), 1))\n        # store\n        predictions.append(yhat)\n        actuals.append(actual)\n    predictions, actuals = vstack(predictions), vstack(actuals)\n    # calculate mse\n    mse = mean_squared_error(actuals, predictions)\n    return mse","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.052540Z","iopub.status.idle":"2023-11-12T19:38:05.052978Z","shell.execute_reply.started":"2023-11-12T19:38:05.052781Z","shell.execute_reply":"2023-11-12T19:38:05.052800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a class prediction for one row of data\ndef predict(row, model):\n    # convert row to data\n    row = Tensor([row])\n    # make prediction\n    yhat = model(row)\n    # retrieve numpy array\n    yhat = yhat.detach().numpy()\n    return yhat","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.055793Z","iopub.status.idle":"2023-11-12T19:38:05.056479Z","shell.execute_reply.started":"2023-11-12T19:38:05.056148Z","shell.execute_reply":"2023-11-12T19:38:05.056180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/nyse/prices.csv'\ntrain_dl, test_dl = prepare_data(path)\nprint(len(train_dl.dataset), len(test_dl.dataset))\n# define the network\nmodel = MLP(4)\n# train the model\ntrain_model(train_dl, model)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.059130Z","iopub.status.idle":"2023-11-12T19:38:05.059583Z","shell.execute_reply.started":"2023-11-12T19:38:05.059380Z","shell.execute_reply":"2023-11-12T19:38:05.059399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # evaluate the model\n# mse = evaluate_model(test_dl, model)\n# print('MSE: %.3f, RMSE: %.3f' % (mse, sqrt(mse)))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.060925Z","iopub.status.idle":"2023-11-12T19:38:05.061309Z","shell.execute_reply.started":"2023-11-12T19:38:05.061123Z","shell.execute_reply":"2023-11-12T19:38:05.061141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make a single prediction R \n# new data \nrow = [54.200001 , 53.630001 , 53.389999 , 54.480000]\nyhat = predict(row, model)\nprint('Predicted: %.3f' % yhat)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T19:38:05.062235Z","iopub.status.idle":"2023-11-12T19:38:05.062652Z","shell.execute_reply.started":"2023-11-12T19:38:05.062433Z","shell.execute_reply":"2023-11-12T19:38:05.062451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}